<html><head><link rel="stylesheet" href="slurm-guide-styles.css"></head><body><h1 id="guide-to-using-slurm"> Slurm User Guide </h1>


<h2>Writing Slurm Job Scripts</h2>

A Slurm job script is a shell script (typically bash) that contains both Slurm directives and the commands you want to run on the cluster. 
Let's break down the components and syntax of a Slurm job script:

<h3>  Basic Structure </h3>

<p>
#!/bin/bash<br>
#SBATCH [options]<br>
#SBATCH [more options]<br>
<br>
# Your commands here<br>
</p>

<h3>  Shebang </h3>

The first line of your script should be the shebang:

<p>
#!/bin/bash
</p>

This tells the system to interpret the script using the bash shell.

<h3>  Slurm Directives </h3>

Slurm directives are special comments that start with `#SBATCH`. They tell Slurm how to set up and run your job. Here are some common directives:

<p>
#SBATCH --job-name=my_job        # Name of the job <br>
#SBATCH --output=output_%j.log   # Standard output log file (%j is replaced by the job ID)<br>
#SBATCH --error=error_%j.log     # Standard error log file<br>
#SBATCH --time=01:00:00          # Time limit (HH:MM:SS)<br>
#SBATCH --ntasks=1               # Number of tasks (processes)<br>
#SBATCH --cpus-per-task=1        # Number of CPU cores per task<br>
#SBATCH --mem=1G                 # Memory limit<br>
#SBATCH --partition=general      # Partition (queue) name<br>
</p>

<h3>  Common Slurm Directives </h3>

Here's a more comprehensive list of Slurm directives:

<li> `--job-name=<name>`: Set a name for the job </li>
 <li>`--output=<filename>`: Specify the file for standard output</li>
 <li>`--error=<filename>`: Specify the file for standard error</li>
 <li>`--time=<time>`: Set a time limit for the job (format: DD-HH:MM:SS)</li>
 <li>`--ntasks=<number>`: Specify the number of tasks to run</li>
 <li>`--cpus-per-task=<number>`: Set the number of CPU cores per task</li>
 <li>`--mem=<size[units]>`: Set the total memory required (e.g., 1G for 1 gigabyte)</li>
 <li>`--partition=<partition_name>`: Specify the partition to run the job on</li>
 <li>`--array=<indexes>`: Create a job array (e.g., --array=1-10 for 10 array jobs)</li>
 <li>`--mail-type=<type>`: Specify email notification events (e.g., BEGIN, END, FAIL)</li>
 <li>`--mail-user=<email_address>`: Set the email address for notifications</li>
 <li>`--nodes=<number>`: Request a specific number of nodes</li>
 <li>`--gres=<resource>`: Request generic consumable resources (e.g., GPUs)</li>

<h3>  Environment Variables </h3>

Slurm sets several environment variables that you can use in your script:

<li>- `$SLURM_JOB_ID`: The ID of the job</li>
<li>- `$SLURM_ARRAY_TASK_ID`: The array index for job arrays</li>
<li>- `$SLURM_CPUS_PER_TASK`: Number of CPUs allocated per task</li>
<li>- `$SLURM_NTASKS`: Total number of tasks in a job</li>

<h3>  Example Job Script </h3>

Here's an example of a more complex Slurm job script:

<p>
#!/bin/bash <br>
#SBATCH --job-name=complex_job<br>
#SBATCH --output=output_%A_%a.log<br>
#SBATCH --error=error_%A_%a.log<br>
#SBATCH --array=1-5<br>
#SBATCH --time=02:00:00<br>
#SBATCH --ntasks=1<br>
#SBATCH --cpus-per-task=4<br>
#SBATCH --mem=8G<br>
#SBATCH --partition=general<br>
#SBATCH --mail-type=BEGIN,END,FAIL<br>
#SBATCH --mail-user=your.email@example.com<br>
<br>
# Load any necessary modules<br>
module load python/3.8<br>
<br>
# Set up the environment<br>
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK<br>
<br>
# Run the main command<br>
python my_script.py --input-file input_${SLURM_ARRAY_TASK_ID}.txt --output-file output_${SLURM_ARRAY_TASK_ID}.txt<br>
<br>
# Optional: Run some post-processing<br>
if [ $? -eq 0 ]; then<br>
    echo "Job completed successfully"<br>
    python post_process.py output_${SLURM_ARRAY_TASK_ID}.txt<br>
else<br>
    echo "Job failed"<br>
fi<br>
<br>
</p>

This script sets up a job array with 5 tasks, each using 4 CPU cores and 8GB of memory. It loads a Python module, sets an environment variable, runs a Python script with task-specific input and output files, and then conditionally runs a post-processing step.

<h3>  Best Practices for Job Scripts </h3>
<ol>
<li>Use variables: For repeated values or for clarity, use shell variables.</li>
<li>Comment your script: Explain complex parts of your script for better maintainability.</li>
<li>Error handling: Include error checking and handling in your script.</li>
<li>Modularity: For complex workflows, consider breaking your job into multiple scripts.</li>
<li>Resource estimation: Start with conservative resource estimates and adjust based on actual usage.</li>
<li>Environment setup: Load necessary modules and set environment variables at the beginning of your script.</li>
<li>Output management: Use job ID and array ID in output file names to avoid overwrites.</li>
</ol>
Remember to write your commands in the LAST part of the script, after you declared all the Slurm directives!
</body>
</html>