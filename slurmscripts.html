<a href="../index.html"></a><html><head><link rel="stylesheet" href="slurm-guide-styles.css"></head><body><h1 id="guide-to-using-slurm"> <a href="../index.html">Slurm User Guide </a></h1>


<h2>Writing Slurm Job Scripts</h2>

A Slurm job script is a shell script (typically bash) that contains both Slurm directives and the commands you want to run on the cluster. 
Let's break down the components and syntax of a Slurm job script:

<h3>  Basic Structure </h3>

<pre class="code">

#!/bin/bash
#SBATCH [options]
#SBATCH [more options]

# Your commands here
</pre>

<h3>  Shebang </h3>

The first line of your script should be the shebang:

<pre class="code">
#!/bin/bash
</pre>

This tells the system to interpret the script using the bash shell.

<h3>  Slurm Directives </h3>

Slurm directives are special comments that start with `#SBATCH`. They tell Slurm how to set up and run your job. Here are some common directives:

<pre class="code">
#SBATCH --job-name=my_job        # Name of the job 
#SBATCH --output=output_%j.log   # Standard output log file (%j is replaced by the job ID)
#SBATCH --error=error_%j.log     # Standard error log file
#SBATCH --time=01:00:00          # Time limit (HH:MM:SS)
#SBATCH --ntasks=1               # Number of tasks (processes)
#SBATCH --cpus-per-task=1        # Number of CPU cores per task
#SBATCH --mem=1G                 # Memory limit
#SBATCH --partition=general      # Partition (queue) name
</pre>

<h3>  Common Slurm Directives </h3>

Here's a more comprehensive list of Slurm directives:

<li> `--job-name=<name>`: Set a name for the job </li>
 <li>`--output=<filename>`: Specify the file for standard output</li>
 <li>`--error=<filename>`: Specify the file for standard error</li>
 <li>`--time=<time>`: Set a time limit for the job (format: DD-HH:MM:SS)</li>
 <li>`--ntasks=<number>`: Specify the number of tasks to run</li>
 <li>`--cpus-per-task=<number>`: Set the number of CPU cores per task</li>
 <li>`--mem=<size[units]>`: Set the total memory required (e.g., 1G for 1 gigabyte)</li>
 <li>`--partition=<partition_name>`: Specify the partition to run the job on</li>
 <li>`--array=<indexes>`: Create a job array (e.g., --array=1-10 for 10 array jobs)</li>
 <li>`--mail-type=<type>`: Specify email notification events (e.g., BEGIN, END, FAIL)</li>
 <li>`--mail-user=<email_address>`: Set the email address for notifications</li>
 <li>`--nodes=<number>`: Request a specific number of nodes</li>
 <li>`--gres=<resource>`: Request generic consumable resources (e.g., GPUs)</li>

<h3>  Environment Variables </h3>

Slurm sets several environment variables that you can use in your script:

<li>- `$SLURM_JOB_ID`: The ID of the job</li>
<li>- `$SLURM_ARRAY_TASK_ID`: The array index for job arrays</li>
<li>- `$SLURM_CPUS_PER_TASK`: Number of CPUs allocated per task</li>
<li>- `$SLURM_NTASKS`: Total number of tasks in a job</li>

<h3>  Example Job Script </h3>

Here's an example of a more complex Slurm job script:

<pre class="code">
    #!/bin/bash 
#SBATCH --job-name=complex_job
#SBATCH --output=output_%A_%a.log
#SBATCH --error=error_%A_%a.log
#SBATCH --array=1-5
#SBATCH --time=02:00:00
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=8G
#SBATCH --partition=general
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=your.email@example.com

# Load any necessary modules
module load python/3.8

# Set up the environment
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

# Run the main command
python my_script.py --input-file input_${SLURM_ARRAY_TASK_ID}.txt --output-file output_${SLURM_ARRAY_TASK_ID}.txt

# Optional: Run some post-processing
if [ $? -eq 0 ]; then
    echo "Job completed successfully"
    python post_process.py output_${SLURM_ARRAY_TASK_ID}.txt
else
    echo "Job failed"
fi

</pre>

This script sets up a job array with 5 tasks, each using 4 CPU cores and 8GB of memory. It loads a Python module, sets an environment variable, runs a Python script with task-specific input and output files, and then conditionally runs a post-processing step.

<h3>  Best Practices for Job Scripts </h3>
<ol>
<li>Use variables: For repeated values or for clarity, use shell variables.</li>
<li>Comment your script: Explain complex parts of your script for better maintainability.</li>
<li>Error handling: Include error checking and handling in your script.</li>
<li>Modularity: For complex workflows, consider breaking your job into multiple scripts.</li>
<li>Resource estimation: Start with conservative resource estimates and adjust based on actual usage.</li>
<li>Environment setup: Load necessary modules and set environment variables at the beginning of your script.</li>
<li>Output management: Use job ID and array ID in output file names to avoid overwrites.</li>
</ol>
Remember to write your commands in the LAST part of the script, after you declared all the Slurm directives!
</body>
</html>